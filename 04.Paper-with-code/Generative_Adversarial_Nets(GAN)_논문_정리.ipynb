{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generative Adversarial Nets(GAN) 논문 정리.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObTNYUXVfB+50+dcU91HIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pthkbs123/SkillTreePython-DeepLearning/blob/main/04.Paper-with-code/Generative_Adversarial_Nets(GAN)_%EB%85%BC%EB%AC%B8_%EC%A0%95%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Nets(GAN) 논문 정리\n",
        "---\n",
        "* 날짜: 2022-08-08\n",
        "* 이름: 박태현"
      ],
      "metadata": {
        "id": "L9Fy0xUt1LPw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Nets 논문 정리"
      ],
      "metadata": {
        "id": "eAyKynLo3y6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abstract"
      ],
      "metadata": {
        "id": "if0GlhHF4fQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저, 현재의 머신러닝을 분류하면 다음과 같다."
      ],
      "metadata": {
        "id": "JzuFoXUm_pDU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://blog.kakaocdn.net/dn/bn0zqv/btreZ1ritXA/sxUN9j2ppcsvjoL6cADmSk/img.png\" width=\"600\" height=\"500\">\n",
        "\n",
        "* 지도학습, 비지도학습, 강화학습"
      ],
      "metadata": {
        "id": "j7kPeusV_bTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 배워왔던 과정은 대부분 지도학습으로, 지도학습은 필수적으로 데이터셋이 필요하다.  \n",
        "하지만 데이터셋은 제작하는 과정에 필연적으로 많은 시간을 소비할 수 밖에 없는데, 이에 따라 각광받은 것이 비지도학습이다.  \n",
        "라벨이 없어도 학습할 수 있으며, 데이터를 직접 생성할 수도 있는 비지도학습이 각광받고 있는데,  \n",
        "그 중에서도 화두에 오른것이 바로 GAN. Generative Adversarial Nets이다."
      ],
      "metadata": {
        "id": "KqlRGfcy_vWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN은 '경쟁‘하는 과정을 통해 generative model을 추정하는 새로운 프레임워크 제안했고, 이때 2개의 모델을 학습한다.  \n",
        "첫 번째는 generative model(생성 모델), G : training data의 분포를 모사하는데, 이는 discriminative model이 구별하지 못하도록 하기 위해서다.  \n",
        "두 번째는 discriminative model(판별모델), D : sample 데이터가 G로부터 나온 데이터가 아닌 실제 training data로부터 나온 데이터일 확률을 추정하기 위서 사용한다.  "
      ],
      "metadata": {
        "id": "S1QlVoeAEnQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "G를 학습하는 과정은 D가 sample 데이터가 G로부터 나온 가짜 데이터와 실제 training 데이터를 판별하는데 실수를 할 확률을 최대화하는 것이며, \n",
        "이 논문에서는 이와 같은 프레임워크를 minimax two-player game으로 표현하고 있다. 이는 논문에서 나오는 방정식으로 확인 가능하다.  \n",
        "임의의 함수 G, D의 공간에서, G가 training 데이터 분포를 모사하게 되면서, D가 실제 training 데이터인지 G가 생성해낸 가짜 데이터인지 판별하는 확률은 1/2가 된다. 즉, 실제 데이터와 G가 생성해내는 데이터의 판별이 어려워진다.  \n",
        "또한 G와 D가 multi-layer perceptrons으로 정의된 경우, 전체 시스템은 back-propagation을 통해 학습된다."
      ],
      "metadata": {
        "id": "dU6XZjOZFjW9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "iVv4BIhK343W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 논문에서 소개되는 adversarial nets 프레임워크의 컨셉은 ‘경쟁’으로, discriminative model은 sample data가 G model이 생성해낸 sample data인지, 실제 training data distribution인지 판별하는 것을 학습한다.  \n",
        "논문에서는 GAN의 경쟁하는 과정을 경찰(분류 모델, 판별자)과 위조지폐범(생성 모델, 생성자) 사이의 경쟁으로 비유하면, 위조지폐범은 최대한 진짜 같은 화폐를 만들어 경찰을 속이기 위해 노력하고, 경찰은 진짜 화폐와 가짜 화폐를 완벽히 판별하여 위조지폐범을 검거하는 것을 목표로 한다. 이러한 경쟁하는 과정의 반복은 어느 순간 위조지폐범이 진짜와 다를 바 없는 위조지폐를 만들 수 있고 경찰이 위조지폐를 구별할 수 있는 확률 역시 50%로 수렴하게 됨으로써 경찰이 위조지폐와 실제 화폐를 구분할 수 없는 상태에 이르도록 한다.  \n",
        "\n",
        "즉, GAN의 핵심 컨셉은 각각의 역할을 가진 두 모델을 통해 적대적 학습을 하면서 ‘진짜같은 가짜’를 생성해내는 능력을 키워주는 것임을 확인할 수 있다."
      ],
      "metadata": {
        "id": "6pN_GUd2GWpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uTPiKyWW4DI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adversarial nets"
      ],
      "metadata": {
        "id": "gC2Wo1Mr4Dle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 초반에는 G가 생성해내는 이미지는 D가 G가 생성해낸 가짜 샘플인지 실제 데이터의 샘플인지 바로 구별할 수 있을 만큼 형편없어, D(G(z))의 결과가 0에 가까움. 즉, z로 부터 G가 생성해낸 이미지가 D가 판별하였을 때 바로 가짜라고 판별할 수 있다고 하는 것을 수식으로 표현한 것이다. 그리고 학습이 진행될수록, G는 실제 데이터의 분포를 모사하면서 D(G(z))의 값이 1이 되도록 발전한다. 이는 G가 생성해낸 이미지가 D가 판별하였을 때 진짜라고 판별해버리는 것을 표현한 것이다. "
      ],
      "metadata": {
        "id": "EOPtH-EfH6q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://firebasestorage.googleapis.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-Lzv9WQqVErrkv4TUmw2%2Fuploads%2FHaQuzfKjH9FwPGzys4Om%2Ffile.png?alt=media\">  \n",
        "\n",
        "좌항 :  real data x를 discriminator 에 넣었을 때 나오는 결과를 log취했을 때 얻는 기댓값  \n",
        "우항 : fake data z를 generator에 넣었을 때 나오는 결과를 discriminator에 넣었을 때 그 결과를 log(1-결과)했을 때 얻는 기댓값"
      ],
      "metadata": {
        "id": "Pp1cFILmH9Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 방정식을 D의 입장, G의 입장에서 각각 이해해보자, \n",
        "* 먼저 D의 입장에서 이 value function V(D,G)의 이상적인 결과를 생각해보면, D가 매우 뛰어난 성능으로 판별을 잘 해낸다고 했을 때, D가 판별하려는 데이터가 실제 데이터에서 온 샘플일 경우에는 D(x)가 1이 되어 첫번째 항은 0이 되어 사라지고 G(z)가 생성해낸 가짜 이미지를 구별해낼 수 있으므로 D(G(z))는 0이 되어 두번째 항은 log(1-0)=log1=0이 되어 전체 식 V(D,G) = 0이 된다. 즉 D의 입장에서 얻을 수 있는 이상적인 결과, '최댓값'은 0임을 확인 할 수 있다.\n",
        "\n",
        "* G의 입장에서 이 value function V(D,G)의 이상적인 결과를 생각해보면, G가 D가 구별못할만큼 진짜와 같은 데이터를 잘 생성해낸다고 했을 때, 첫번째 항은 D가 구별해내는 것에 대한 항으로 G의 성능에 의해 결정될 수 있는 항이 아니므로 패스하고 두번째 항을 살펴보면 G가 생성해낸 데이터는 D를 속일 수 있는 성능이라 가정했기 때문에 D가 G가 생성해낸 이미지를 가짜라고 인식하지 못하고 진짜라고 결정내버린다. 그러므로 D(G(z)) =1이 되고 log(1-1)=log0=마이너스무한대가 된다. 즉, G의 입장에서 얻을 수 있는 이상적인 결과, '최솟값'은 '마이너스무한대'임을 확인할 수 있다."
      ],
      "metadata": {
        "id": "uEuTuA0uPE9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "다시말해, D는 training data의 sample과 G의 sampl에 진짜인지 가짜인지 올바른 라벨을 지정할 확률을 최대화하기 위해 학습하고, G는 log(1-D(G(z))를 최소화(D(G(z))를 최대화)하기 위해 학습되는 것이다.  \n",
        "D입장에서는 V(D,G)를 최대화시키려고, G입장에서는 V(D,G)를 최소화시키려고 하고, 논문에서는 D와 G를 V(G,D)를 갖는 two-player minmax game으로 표현하는 것이다."
      ],
      "metadata": {
        "id": "alM9t2szP0FY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://firebasestorage.googleapis.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-Lzv9WQqVErrkv4TUmw2%2Fuploads%2F39NU70gaap9JBh5zqwX8%2Ffile.png?alt=media\">  \n",
        "* 파란색 점선: discriminative distribution\n",
        "* 검은색 점선: data generating distribution(real)\n",
        "* 녹색 실선: generative distribution(fake)"
      ],
      "metadata": {
        "id": "xrwzLmCIQEgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN의 학습과정을 이 그림을 통해 확인해보면,  \n",
        "(a): 학습초기에는 real과 fake의 분포가 전혀 다름. D의 성능도 썩 좋지 않음  \n",
        "(b): D가 (a)처럼 들쑥날쑥하게 확률을 판단하지 않고, 흔들리지 않고 real과 fake를 분명하게 판별해내고 있음을 확인할 수 있으며, 이는 D가 성능이 올라갔음을 확인 가능  \n",
        "(c): 어느정도 D가 학습이 이루어지면, G는 실제 데이터의 분포를 모사하며 D가 구별하기 힘든 방향으로 학습을 함  \n",
        "(d): 이 과정의 반복의 결과로 real과 fake의 분포가 거의 비슷해져 구분할 수 없을 만큼 G가 학습을 하게되고 결국, D가 이 둘을 구분할 수 없게 되어 확률을 1/2로 계산하게 된다."
      ],
      "metadata": {
        "id": "_cclSVo3QRoY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theoretical Results"
      ],
      "metadata": {
        "id": "_Vm_0qqGQ9SY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앞서 제시되었던 GAN의 minmax problem이 제대로 작동 한다면, minmax problem이 global minimum에서 unique solution을 가지고 어떠한 조건에 만족하면 그 solution으로 수렴한다는 사실이 증명되어야 한다. 총 두 가지의 증명이 필요한데, 이번에는 논문의 4-1, Global Optimality of Pg = Pdata만 공부해봤다."
      ],
      "metadata": {
        "id": "br6kSXhURD7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Optimality of Pg = Pdata"
      ],
      "metadata": {
        "id": "K-CG2X8HRPOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "증명을 깔끔하게 한 이미지가 있어 가져왔다.\n",
        "\n",
        "<img src=\"https://firebasestorage.googleapis.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-Lzv9WQqVErrkv4TUmw2%2Fuploads%2FtsUP8s0jBP5R5UOtumPP%2Ffile.jpeg?alt=media\">  \n",
        "<img src=\"https://firebasestorage.googleapis.com/v0/b/gitbook-x-prod.appspot.com/o/spaces%2F-Lzv9WQqVErrkv4TUmw2%2Fuploads%2FZKHQkSOiDf1fTidSb4os%2Ffile.jpeg?alt=media\">  "
      ],
      "metadata": {
        "id": "_B_jveAdRV-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsH80i_91Fru"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 출처 밎 참고\n",
        "* https://tobigs.gitbook.io/tobigs/deep-learning/computer-vision/gan-generative-adversarial-network\n",
        "* https://roytravel.tistory.com/109"
      ],
      "metadata": {
        "id": "WQrFCMFHOA_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1-N5FSn5OEbQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}